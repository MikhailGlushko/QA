## 1. В чем разница между потоком и процессом?
>Процесс является более высокоуровневой абстракцией ОС для выполнения программы, чем поток. Он, в свою очередь, может запускать в себе несколько потоков.
>
>Процесс всегда имеет хотя бы один (главный) поток.

## 2. Что такое кооперативная многозадачность и она ли в Java. Если да, то какие преимущества. Если нет, то какая тогда в Java?
>Кооперативная многозадачность - это техника конкурентного выполнения программ, в которой обязанность передачи управления перекладывается на саму программу.
>
>Преимущество кооперативной многозадачности заключается в большей надежности и предопределенности выполнения программ, так как при таком подходе программа сама контролирует последовательность выполнения задач.
>
>В Java вытесняющая многозадачность.

## 3. Сравните кооперативную и вытесняющую многозадачности
>При вытесняющей многозадачности по таймеру, который генерирует прерывания через определенные промежутки времени(~ 1мс), операционная система передает управление планировщику. Планировщик выбирает задачу из очереди и передает управление этой задачи. Задача выполняется определенное количество времени и безусловно прерывается.
>
>При вытесняющей многозадачности программа после завершения работы уведомляет операционную систему, что она завершила работу и можно передать управление другой программе.
>
>Преимущества кооперативной многозадачности:
> - Полный контроль за выполнением программы. 
>
>То есть программисты такой системы знают, что программа не будет прервана посередине выполнения важной задачи. Это критично для систем с жесткими гарантиями по времени выполнения.
>
> - Программа получает в свое распоряжение все системные ресурсы.
> - Реализация операционной системы с кооперативной многозадачностью проще, чем с вытесняющей.
>
>Преимущества вытесняющей многозадачности:
> - Программа, написанная с ошибками, не заберет себе все ресурсы сервера. Планировщик принудительно прервет ее выполнение и передаст управление другому процессу.
>
> - Возможность эмуляции параллельной работы нескольких программ. Система не "зависает", пока одна из программ выполнят свою задачу.
>
>То есть задача, потребляющая большое количество процессорного времени, не заберет себе все ресурсы и не заблокирует систему от выполнения другой активности.
>
> - Программирование на системах с вытесняющей многозадачностью проще, так как программисту не нужно думать о том, как и когда отдавать управление операционной системе. Она сама заботится об этом.
>
>Системы общего назначения обычно используют вытесняющую многозадачность. В то же время, системы с жестким временем выполнения (медицинское,автомобильное, аэрокосмическое оборудование) полагаются на кооперативную многозадачность.

## 4. Что такое «зеленый потоки» и они ли в Java (в HotSpot JVM 7)?
>"Зеленые потоки" - это потоки, которыми управляет виртуальная машина, а не операционная система. Они дают возможность эмулировать многопоточность внутри процесса без переключения контекста между пользательским режимом и режимом ядра.
>
>Преимущество зеленых потоков заключается в том, что они легче, чем системные потоки (не нужно сохранять стек на каждый поток и ходить в режим ядра для переключения). Программист может создавать тысячи зеленых потоков, в то время как у системных потоков есть практическое ограничение на их количество. Это может быть полезно в случае, если задача не ограничена процессорным временем, но выполняет частый ввод-вывод. В этом случае затраты на переключение между потоками будут намного меньше, при этом 
программист имеет абстракцию последовательного выполнения кода.
>
>Нет, в Java потоки маппятся 1 в 1 на системные потоки.

## 5. Когда началась «Multicore Era»?
>В начале 2000-х с появлением процессорорв серии POWER от IBM. Затем в 2005 появились Pentium D и AMD Athlon 64 X2.
>
>Связано с тем, что частота процессоров больше не могла расти из-за физических ограничений и технологических проблем, возникающих при увеличинии плотности транзисторов на поверхности кристалла.
>
>Классическая статья - http://www.gotw.ca/publications/concurrency-ddj.htm[The Free Lunch Is Over]

## 6. Что такое — Планировщик потоков? Предположите алгоритм работы?
>Планировщик потоков - программа на уровне операционной системы, которой по прерыванию управление через определенные промежутки времени. Ее задача - распределять процессорное время между процессами, выполняющимся в системе.
>
> * Заводится кольцевой буфер;
> * Когда процесс начинает работу, он добавляется в буфер;
> * Когда заканичивает - удаляется;
> * Планировщик выбирает процесс с головы буфера;
> * Голова буфера сдвигается к следующему процессу;
> * Процесс выполняется свой квант времени;
> * Текущий процесс прерывается;
> * Управление передается процессу в голове буфера

## 7. Какие выигрыши может дать многопоточность на одноядерной машине?
> * Возможность "практически одновременно" выполнять несколько задач;
> * Лучшая "отзывчивость" систем, для которых более важен быстрый ответ, а не общее количество выполненной работы;
> * Более быстрое выполнение задач, которые не ограничены процессорным временем.
>Скажем, у нас есть n задач, которые выполняют I/O (чтение из сети) и они не связаны между собой. В этом случае мы можем их параллельно запустить и обрабатывать результаты каждой задачи, только когда они будут готовы. Если бы эти задачи выполнялись параллельно, то мы бы тратили процессорное время на задержки сети. 

## 8. Что такое Flynn’s taxonomy, SISD/MISD/SIMD/MIMD? К какому классу относятся CPU?
>_Таксономия Флинна_ - это классификация вычислительных архитектур по типу параллельных инструкций и потоков данных.
>
> * SISD - вычислительные системы с одним потоком данных и одним потоком инструкций (типичиная архитектура для одноядерных процессоров).
> * MISD - вычислительные системы с одним потоком данных и несколькими потоками инструкций (довольно редкая архитектура). 
> * SIMD - вычислительные системы с несколькими потоками данных и одним потоком инструкций (векторные процессоры, GPU).
> * MIMD - вычислительные системы с несколькими потоками данных и несколькими потоками инструкций (распределенные системы).
>
>Одноядерные процессоры относятся к SISD системам, многоядерные процессоры к SIMD или MIMD. GPU является SIMD системой, потому что использует векторные инструкции для операций над мультимедиа-данными.

## 9. Расскажите про иерархию кэшей L1/L2/L3? Что вызвало ее появление
>L1/L2/L3 - кэши данных, которыми оперирует процессор.
>
> * L1 - кэш на ядре процессора с скоростью доступа порядка 1 нс. Размер обычно около 32 КБ.
> * L2 - более крупный и менее быстрый кэш. Скорость доступа порядка 5 нс. Размер порядка 256 КБ.
> * L3 - кэш на процессоре, общий для всех ядер. Скорость доступа порядка 20 нс. Может быть достаточно большим (8-32 MB). 
>
>Появление кэшей вызывало тот факт, что скорость работы процессора начала становится намного больше скорости доступа к памяти. Поэтому для того, чтобы избежать огромных задержек по доступу к данным из основной памяти (порядка 60 нс), производителями процессоров были добавлены кэши на процессорах для быстрого выполнения операций над "горячими" данными. 

## 10. Что такое Memory wall?
>_Memory wall_ - это термин, описавающий ограничение производительности вычислительных систем скоростью доступа к памяти. Несмотря на то, что частота процессоров в 70-90-е годы увеличивалась в 2 раза каждые 2 года, скорость доступа к памяти не увеличивалсь с такой же степенью. 
>
>В итоге производительность системы в целом упиралась в производительности памяти, так как процессоры не могли работать на своей полной вычислительной мощности.

## 11. Что такое Memory Hierarchy?
>_Memory Hierarchy_ - термин для описания производительности систем хранения данных. Чем ниже уровень иерархии, тем дешевле цена системы хранения и больше время доступа к ней. Обычно выделяют 4 уровня:
>
> * Регистры и кэши процессора (скорость доступа порядка 100-500 Гб/c)
> * Оперативная память (скорость доступа порядка 1-10 Гб/c)
> * Диски (скорость доступа порядка 100-500 Мб/c)
> * Третичные память (скорость доступа порядка 10-100 Мб/c)

## 12. Что такое Cache line? В виде каких эффектов проявляется?
>_Cache line_ - блок данных(обычно 64 байт), в котором передаются данные между процессором и оперативной памятью. Когда процессору нужно прочитать данные по конкретному адресу из опертивной памяти, он вместо 1 байта читает сразу блок данных и кладет этот блок в кэш. 
>
>Такая оптимизация хорошо работает в случае, если данные, над которыми работает процессор, обладают хорошей локальностью. Тогда при следующем чтении данные уже будут в кэше и процессору не нужно будет делать дорогой запрос в оперативную память.

## 13. Что такое False sharing? Плохо это или хорошо? Как с этим бороться?
>_False sharing_ - эффект при котором данные, не связанные с друг другом, попадают в одну кэш-линию. В итоге когда изменяется одна из частей данных в кэш-линии, вся линия инвалидируется. Это плохой эффект, так как он может вызывать трешинг (thrashing) - постоянную подгрузку и инвалидацую данных их кэша. Например, часто читаемые данные могут попать на одну линию с часто записываемыми. При каждой записи линия будет инвалидироваться из кэша вместе с часто читаемыми данными, хотя сами данные не менялись.
>
>Бороться можно с помощью техники паддинга (padding). Часто читаемые данные выравниваются по модулю длины кэш-линии с помощью фиктивных байтов. В итоге исключается вариант, когда вместе с ними на кэш-линию попадают "случайные" данные.

## 14. Что такое Memory padding?
>_Memory padding_ - это техника выравнивая структуры данных по границам читаемого процессором размера слова. Она позволяет быть уверенным, что данные всегда попадут на одну кэш-линию и займут ее экслюзивно. Это позволяет избежать трешинга кэша, в случае, если на линию попадают не соотносящиеся друг с другом данные.

## 15. Что такое Cache pollution? Плохо это или хорошо? Как с этим бороться?
>_Cache pollution_ - эффект при котором, происходит трешинг кэшей из-за того, что активные данные не имеют локальности. Если данные на находятся на одной кэш-линии, то при чередующем обращении к 1-му и 2-му набору данных, кэш будет постоянно инвалидировать и подгружать данные.
>
>Это плохой эффект, так как он может привести к заметному падению производительности приложения без видимой для программиста причины. 
>
>Бороться можно изменением подхода к обработке данных. Идея заключается в том, чтобы в один период времени работать только с "горячими" данными в кэше и начинать работу со следующим набором данных только после того, как первый больше не нужен.
